{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b1cb43-3be1-4f87-8c26-581f591afdce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <center><strong><span style= 'color: #51fcc6'>Notebook </span>Describtion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922ce52-f8a8-47c3-b1fa-a8fdc1eaa87e",
   "metadata": {},
   "source": [
    "Here we will try to extract more data from the describtions of each job using simple NER, POS & Regex expressions<br>\n",
    "We will also need to clean the data after we extract it and make sure that there isn't any NANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1713b-7169-4322-bc7b-f8c5acc5dfcc",
   "metadata": {},
   "source": [
    "**Things we will extract from the dexcribtions:**\n",
    "- Salaries data\n",
    "- Mentioned skills\n",
    "- Requeird years of experience\n",
    "- Requeird programming languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484e990-2723-45e1-92cf-3a59f97a2af8",
   "metadata": {},
   "source": [
    "## <center><strong>Importing the <span style= 'color: #48e0dc'>Packeges</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce9d4d17-4dbd-4c66-b031-8a00b62a4b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib\n",
    "\n",
    "import pandas             as pd\n",
    "import numpy              as np\n",
    "import seaborn            as sns\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "from io                   import StringIO \n",
    "from bs4                  import BeautifulSoup\n",
    "from google.cloud         import bigquery\n",
    "from wordcloud            import WordCloud\n",
    "from IPython.display      import set_matplotlib_formats\n",
    "from collections          import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a93668f-55d4-4a1f-80a7-bb55ab0ba449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'Candara'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "credentials_path :str = '../credentials.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
    "\n",
    "FONT             :int  = 17\n",
    "COLORS           :list = ['#51fcc6', '#48e0dc', '#5cd3f7', '#4895e0', '#517afc']\n",
    "NUMERICS         :list = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64',\n",
    "                          'uint16', 'uint32', 'uint64']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e6b0e-1e94-4f3a-a984-86ecc216d425",
   "metadata": {},
   "source": [
    "## <center><strong>Exploring the data from <span style= 'color: #48e0dc'>Text</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6ff15e2b-3516-4616-b543-0476c0e90879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FreeComp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\FreeComp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\FreeComp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\FreeComp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5210b397-3315-4f5f-97d7-a49f3040d50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id :str = 'data-jobs-analysis-db'\n",
    "dataset_id :str = 'data_jobs_analysis_db'\n",
    "\n",
    "client   = bigquery.Client(project= project_id)\n",
    "\n",
    "linkedin_jobs    = client.query(f'SELECT * FROM {dataset_id}.linkedin_jobs;').to_dataframe()\n",
    "upwork_profiles  = client.query(f'SELECT * FROM {dataset_id}.upwork_profiles;').to_dataframe()\n",
    "guru_profiles    = client.query(f'SELECT * FROM {dataset_id}.guru_profiles;').to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87fdd6d5-784b-47b9-88e0-132461b49cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3455 entries, 0 to 3454\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   jobs_locations      3455 non-null   object\n",
      " 1   listing_dates       3349 non-null   object\n",
      " 2   jobs_titles         3455 non-null   object\n",
      " 3   companies_names     3455 non-null   object\n",
      " 4   jobs_links          3455 non-null   object\n",
      " 5   describtion         3455 non-null   object\n",
      " 6   location_type       3455 non-null   object\n",
      " 7   employment_type     3455 non-null   object\n",
      " 8   industry            3414 non-null   object\n",
      " 9   reqierd_credential  3455 non-null   object\n",
      " 10  country             3455 non-null   object\n",
      " 11  job_title           3455 non-null   object\n",
      " 12  total_jobs          3455 non-null   Int64 \n",
      "dtypes: Int64(1), object(12)\n",
      "memory usage: 354.4+ KB\n"
     ]
    }
   ],
   "source": [
    "linkedin_jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc027bf8-0d74-46c0-a2e4-4634387b0595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \n",
    "    text_with_raw_html : str = BeautifulSoup(text, 'lxml').text\n",
    "    text               : str = BeautifulSoup(text_with_raw_html, 'lxml').text\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "806f16d6-d6b7-47d6-a86d-13e6a2d57e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_salary(description) -> float:\n",
    "    \n",
    "    salary_regex = r'\\$([0-9,.]+(?:K|k)?(?:\\.\\d+)?)(?:\\s*(?:to|-)\\s*\\$([0-9,.]+(?:K|k)?(?:\\.\\d+)?))?'\n",
    "    salary_matches = re.findall(salary_regex, description)\n",
    "\n",
    "    \n",
    "    if salary_matches:\n",
    "        salary_range = tuple(float(value.replace(',', '').replace('.', '').lower().replace('k', '000')) for value in salary_matches[0] if value != '' )\n",
    "        salary = sum(salary_range) / len(salary_range)\n",
    "    else:\n",
    "        salary = np.nan\n",
    "\n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d0e9f-e04d-4cc1-97c5-e2854d5fd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_requird_exp_years(description) -> float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37830406-090a-436c-8079-75656a996d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_requird_skills(description) -> list:\n",
    "\n",
    "    data_analysis_skills = [\n",
    "        'Pandas', 'Excel',\n",
    "        'NumPy', 'Matplotlib',\n",
    "        'Seaborn', 'Tableau',\n",
    "        'Power BI', 'Data querying',\n",
    "        'Data mining', 'Data interpretation',\n",
    "        'Data modeling', 'Data reporting',\n",
    "        'Business intelligence', 'Data analytics',\n",
    "        'Data validation', 'Data profiling',\n",
    "        'Data aggregation', 'Data imputation',\n",
    "        'Data manipulation', 'Data auditing',\n",
    "        'Data quality management',\n",
    "        'Data cleaning', 'Data visualization',\n",
    "        'Statistical analysis', 'SPSS']\n",
    "\n",
    "    data_science_skills = [\n",
    "        'Machine learning', 'Deep learning', 'NLP',\n",
    "        'Natural language processing', 'Computer vision',\n",
    "        'Big data', 'Data wrangling',\n",
    "        'Feature engineering', 'Predictive modeling',\n",
    "        'Time series analysis', 'TensorFlow',\n",
    "        'Keras', 'PyTorch',\n",
    "        'Scikit-learn', 'Hadoop',\n",
    "        'Spark', 'Data storytelling',\n",
    "        'A/B testing', 'Data mining',\n",
    "        'Data cleaning', 'Data visualization',\n",
    "        'Data manipulation', 'Data pre-processing',\n",
    "        'Data analysis', 'Data presentation',\n",
    "        'Data-driven decision making', 'Model evaluation',\n",
    "        'Model deployment']\n",
    "\n",
    "    data_engineering_skills = [\n",
    "        'ETL (Extract, Transform, Load)',\n",
    "        'Data warehousing', 'Data pipelines',\n",
    "        'Database management', 'Data architecture',\n",
    "        'Data integration', 'Apache Kafka',\n",
    "        'Apache Airflow', 'Amazon Web Services',\n",
    "        'Google Cloud Platform', 'Microsoft Azure',\n",
    "        'Docker', 'Kubernetes',\n",
    "        'Data security', 'Data governance',\n",
    "        'Data scalability', 'Data storage',\n",
    "        'Data migration', 'Data transformation',\n",
    "        'Data orchestration', 'Data monitoring',\n",
    "        'Data lake', 'AWS', 'GCP']\n",
    "\n",
    "    data_entry_skills = [\n",
    "        'Typing speed', 'Data accuracy',\n",
    "        'Data entry software', 'Excel',\n",
    "        'Google Sheets', 'Data verification',\n",
    "        'Data organization', 'Attention to detail',\n",
    "        'Time management', 'Data maintenance',\n",
    "        'Database management', 'Copy typing',\n",
    "        'Data review', 'Data formatting',\n",
    "        'Data categorization', 'Data entry validation',\n",
    "        'Data cleansing', 'Data input',\n",
    "        'Data indexing', 'Data extraction',\n",
    "        'Data capture', 'Data filing',\n",
    "        'Data archiving']\n",
    "\n",
    "    all_skills = (\n",
    "        data_analysis_skills + data_science_skills +\n",
    "        data_engineering_skills + data_entry_skills)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "377b70b4-1df6-45de-83e1-9b7e415f54b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linkedin_jobs['describtion'] : pd.Series = linkedin_jobs['describtion'].apply(remove_html_tags)\n",
    "linkedin_jobs['salary']      : pd.Series = linkedin_jobs['describtion'].apply(extract_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "59b9fc00-21ba-41f1-8a65-f5ca80f267aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description_tokenized = nltk.Text(nltk.word_tokenize(linkedin_jobs['describtion'][3000]))\n",
    "description_tokenized.concordance('$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "97cbde67-04ea-492b-b518-2c5fb15612f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110000.0"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_salary(linkedin_jobs['describtion'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "c6c0512b-c154-4ca4-b79a-1be7655cf11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1           25.0\n",
       "2       110000.0\n",
       "3            NaN\n",
       "4            NaN\n",
       "5            NaN\n",
       "6            NaN\n",
       "7            NaN\n",
       "8            NaN\n",
       "9           72.5\n",
       "10          40.0\n",
       "11        4667.0\n",
       "12           NaN\n",
       "13           NaN\n",
       "14           NaN\n",
       "15           NaN\n",
       "16           NaN\n",
       "17          37.5\n",
       "18           NaN\n",
       "19      139860.0\n",
       "20      147500.0\n",
       "21      176000.0\n",
       "22      176000.0\n",
       "23           NaN\n",
       "24           NaN\n",
       "25       82500.0\n",
       "26     9900000.0\n",
       "27           NaN\n",
       "28           NaN\n",
       "29      125000.0\n",
       "30    10100000.0\n",
       "31      135500.0\n",
       "32         300.0\n",
       "33       90000.0\n",
       "34       90000.0\n",
       "35           NaN\n",
       "36           NaN\n",
       "37          38.0\n",
       "38           NaN\n",
       "39          63.0\n",
       "40          63.0\n",
       "41           NaN\n",
       "42           NaN\n",
       "43           NaN\n",
       "44           NaN\n",
       "45           NaN\n",
       "46          60.0\n",
       "47           NaN\n",
       "48           NaN\n",
       "49           NaN\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_jobs['salary'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "92e5c991-89ec-443b-8dca-41fc4c6ea47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('fesd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e107dcdd-ee77-4de7-acdb-e5d8ffdf8a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1         27.5\n",
       "2          4.0\n",
       "3          NaN\n",
       "4          NaN\n",
       "5          9.0\n",
       "6          1.0\n",
       "7          1.0\n",
       "8          NaN\n",
       "9         72.5\n",
       "10         5.0\n",
       "11         NaN\n",
       "12         NaN\n",
       "13         NaN\n",
       "14         NaN\n",
       "15         NaN\n",
       "16         NaN\n",
       "17        37.5\n",
       "18         NaN\n",
       "19         8.5\n",
       "20    147500.0\n",
       "21    176000.0\n",
       "22    176000.0\n",
       "23        11.5\n",
       "24         NaN\n",
       "25     82500.0\n",
       "26     99000.0\n",
       "27         NaN\n",
       "28         NaN\n",
       "29         NaN\n",
       "Name: describtion, dtype: float64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_jobs['describtion'][:30].apply(extract_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "e73b8042-360b-41b2-ba88-beaa2f0d86f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data EngineerNew Jersey Connecticut Chelmsford, MassachusettsDescriptionJob ID: 23-579What You'll Be Working OnDetermine internal / external customer data needs and identify system specificationsAnalyze the needs of large systems and breaking them down into smaller manageable partsResponsible for designing the journey of data from various sources to the database and everything in betweenPlan and design the structure of data, brainstorm with teamAnalyze best technology products and systems for internal teamsHelp provide build vs buy decisions on data architectureCommunicate data requirements to engineers; explain data architecture to them and provide assistance throughout SDLCChoose / maintain suitable software, hardware and integration methodsHelp resolve technical problems as and when they ariseReview testing procedures to ensure data performant and error freeEnsure that database satisfy quality standards and procedures. Setup such standards. Work with senior IT personnel to devise plans for future IT requirements of the organizationProduce progress reports on key infrastructures - Elastic and Data PipelinesWhat You Bring To The RoleBachelor Degree or Post Graduate in Computer Science, or relevant work experience5+ years of experience in an Engineering / Operations heavy organization 1+ years of experience as a Data Analysis and Data Design responsible for data architecture of a SaaS application Experience in understanding and designing data sharding in a distributed databaseSome Hands-on experience in software development and system administrationKnowledge of strategic IT solutionsFamiliarity with programming languages like JavaScript or Java or PythonFamiliarity with Linux OS and Windows alikeExperience in cloud computing and cloud Technologies (AWS, GCP, Azure) Excellent communication skills - you should be adept at listening to, understanding, and explaining key concepts to managerial and technical resources.Good Anticipation and problem-solving skillsAbility to prioritize and manage time - responsible for multiple streams of work at the same timeRelationship building - Ability to form a good rapport with internal and external stakeholdersIn-depth knowledge about quality standards and security best practicesPreferred Skills Expert level Understanding of Elastic eco system - Elasticsearch, Logstash, Kibana, FilebeatsUnderstanding of secure tunnel communication using VPNExperience designing data at scaleAWS experience is preferred in Cloud TechnologiesWhat You'll Get From UsA team where you can voice your opinion, make an impact, and where you and your experience are valued. Internal mobility - there are opportunities for cross training and the ability to attain your next career step within Barracuda.Equity, in the form of non-qualified optionsHigh-quality health benefitsRetirement Plan with employer matchCareer-growth opportunitiesFlexible Time Off and Paid Time Off benefitsVolunteer opportunitiesApplicants must be authorized to work in the U.S.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!Looking forward to receiving your resume and going over the position in more detail with you.The Platinum Team!Platinum is proud to be an Equal Opportunity EmployerPESOL is an EEO employer. All qualified applicants will receive consideration without regard to race, color, religion, sex, pregnancy, national origin, disability, age, genetic information, veteran status, sexual orientation and identity, AIDS/HIV, medical condition, political activities or affiliations, or status as a victim of domestic violence, assault, or stalking.Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.Copyright Â© 2006 - 2018. Platinum ESOL, Inc. All rights reserved.\""
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_jobs['describtion'][3451]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e773580d-0528-4b3c-9c32-39e5fd24f802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World\\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e74750-c9a6-4de5-b00a-a69628f3d194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
