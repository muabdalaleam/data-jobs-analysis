{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b1cb43-3be1-4f87-8c26-581f591afdce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <center><strong><span style= 'color: #51fcc6'>Notebook </span>Describtion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922ce52-f8a8-47c3-b1fa-a8fdc1eaa87e",
   "metadata": {},
   "source": [
    "Here we will try to extract more data from the describtions of each job using simple NER, POS & Regex expressions<br>\n",
    "We will also need to clean the data after we extract it and make sure that there isn't any NANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1713b-7169-4322-bc7b-f8c5acc5dfcc",
   "metadata": {},
   "source": [
    "**Things we will extract from the dexcribtions:**\n",
    "- Salaries data\n",
    "- Mentioned skills\n",
    "- Requeird languages <sub>*(Natural languages)</sub>\n",
    "- Requeird years of experience\n",
    "- Requeird or prefered degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484e990-2723-45e1-92cf-3a59f97a2af8",
   "metadata": {},
   "source": [
    "## <center><strong>Importing the <span style= 'color: #48e0dc'>Packeges</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9d4d17-4dbd-4c66-b031-8a00b62a4b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "import warnings\n",
    "import matplotlib\n",
    "import pandas             as pd\n",
    "import numpy              as np\n",
    "import seaborn            as sns\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "from bs4                  import BeautifulSoup\n",
    "from google.cloud         import bigquery\n",
    "from wordcloud            import WordCloud\n",
    "from IPython.display      import set_matplotlib_formats\n",
    "from collections          import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a93668f-55d4-4a1f-80a7-bb55ab0ba449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'Candara'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "credentials_path :str = '../credentials.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
    "\n",
    "FONT             :int  = 17\n",
    "COLORS           :list = ['#51fcc6', '#48e0dc', '#5cd3f7', '#4895e0', '#517afc']\n",
    "NUMERICS         :list = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64',\n",
    "                          'uint16', 'uint32', 'uint64']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e6b0e-1e94-4f3a-a984-86ecc216d425",
   "metadata": {},
   "source": [
    "## <center><strong>Exploring the <span style= 'color: #48e0dc'>Text</span> data\n",
    "<sub>*And clean the text data.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff15e2b-3516-4616-b543-0476c0e90879",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5210b397-3315-4f5f-97d7-a49f3040d50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id :str = 'data-jobs-analysis-db'\n",
    "dataset_id :str = 'data_jobs_analysis_db'\n",
    "\n",
    "client   = bigquery.Client(project= project_id)\n",
    "\n",
    "linkedin_jobs    = client.query(f'SELECT * FROM {dataset_id}.linkedin_jobs;').to_dataframe()\n",
    "upwork_profiles  = client.query(f'SELECT * FROM {dataset_id}.upwork_profiles;').to_dataframe()\n",
    "guru_profiles    = client.query(f'SELECT * FROM {dataset_id}.guru_profiles;').to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87fdd6d5-784b-47b9-88e0-132461b49cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3455 entries, 0 to 3454\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   jobs_locations      3455 non-null   object\n",
      " 1   listing_dates       3349 non-null   object\n",
      " 2   jobs_titles         3455 non-null   object\n",
      " 3   companies_names     3455 non-null   object\n",
      " 4   jobs_links          3455 non-null   object\n",
      " 5   describtion         3455 non-null   object\n",
      " 6   location_type       3455 non-null   object\n",
      " 7   employment_type     3455 non-null   object\n",
      " 8   industry            3414 non-null   object\n",
      " 9   reqierd_credential  3455 non-null   object\n",
      " 10  country             3455 non-null   object\n",
      " 11  job_title           3455 non-null   object\n",
      " 12  total_jobs          3455 non-null   Int64 \n",
      "dtypes: Int64(1), object(12)\n",
      "memory usage: 354.4+ KB\n"
     ]
    }
   ],
   "source": [
    "linkedin_jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc027bf8-0d74-46c0-a2e4-4634387b0595",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       We are seeking a Data Engineer to join the Arc...\n",
       "1       Job Title: Entry Level Data AnalystbrbrLocatio...\n",
       "2       Oakland - California - United States of Americ...\n",
       "3       San Francisco - California - United States of ...\n",
       "4       Dice is the leading career destination for tec...\n",
       "                              ...                        \n",
       "3450    strongemSmile Identity builds trust./em/strong...\n",
       "3451    Data Engineerpbr/pNew Jersey Connecticut Chelm...\n",
       "3452    F_IT EIA Core and Compliancepbr/pFull Timepbr/...\n",
       "3453    Positions: 1 Full Time Associate, Mid-Senior l...\n",
       "3454    strongTitle: Cloud technologies/Data Analytics...\n",
       "Name: describtion, Length: 3455, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    cleantext = re.sub(CLEANR, '', text)\n",
    "    return cleantext\n",
    "\n",
    "linkedin_jobs['describtion'].dropna().apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806f16d6-d6b7-47d6-a86d-13e6a2d57e29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to my Upwork digital portfolio!  \\nFor quick insights and to save you time, I have summarized key points of my Data Professional career as follows:\\n✅ 4+ years of Azure experience\\n     ✔️ Azure Data warehouse | Azure SQL databases\\n     ✔️ Azure Data Factory \\n     ✔️ Azure Synapse Analytics\\n     ✔️ Microsoft PowerBI \\n     ✔️ PowerBI integration with Azure Synapse \\n✅ 2+ years of Google Cloud experience\\n     ✔️ BigQuery Expert\\n     ✔️ Google Data Studio \\n✅ 2+ years of AWS databases experience \\n     ✔️ PostgreSQL | SQL Server databases migration\\n     ✔️ MySQL database optimization\\n\\nUPWORK INSIGHTS \\n\\n✅ 5+ Upwork Enterprise/corporate clients\\n✅ $100k+ Earnings\\n✅ 4000+ Work hours\\n✅ 200+ completed jobs\\n\\nAbout Me:\\nI am a Certified Azure Data Engineer with 4+ years of corporate experience working on Azure SQL databases, Azure Data Factory Data Pipelines, Azure Synapse Analytics, Enterprise level Data Warehousing and Linked Services via Azure Synapse Analytics, and data visualizations using PowerBI. I have been delivering data-related projects with end-to-end services provided as follows:\\n- Requirements gathering\\n- Data analysis\\n- ETL data pipelines\\n- Data ingestion, data wrangling, and cleaning\\n- Data modeling and databases\\n- Data Analysis\\n- Data Visualization\\n \\nHobbies:\\n📖 Books Reading\\n🎮 Snooker \\n🏓Table Tennis'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upwork_profiles['describtion'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70e5c659-f9ae-4469-9598-ffe65fb12be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tree.read(): expected '(' but got '['\n            at index 0.\n                \"[('Welcome...\"\n                 ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Step 2: Perform POS tagging\u001b[39;00m\n\u001b[0;32m     10\u001b[0m tag \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mpos_tag(tokens)\n\u001b[1;32m---> 12\u001b[0m pos_tree \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromstring\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Step 2: Display the POS tree\u001b[39;00m\n\u001b[0;32m     15\u001b[0m pos_tree\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\tree\\tree.py:680\u001b[0m, in \u001b[0;36mTree.fromstring\u001b[1;34m(cls, s, brackets, read_node, read_leaf, node_pattern, leaf_pattern, remove_empty_top_bracketing)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# Leaf node\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m         \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopen_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m read_leaf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m         token \u001b[38;5;241m=\u001b[39m read_leaf(token)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\tree\\tree.py:731\u001b[0m, in \u001b[0;36mTree._parse_error\u001b[1;34m(cls, s, match, expecting)\u001b[0m\n\u001b[0;32m    729\u001b[0m     offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m13\u001b[39m\n\u001b[0;32m    730\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m, s, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m17\u001b[39m \u001b[38;5;241m+\u001b[39m offset))\n\u001b[1;32m--> 731\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Tree.read(): expected '(' but got '['\n            at index 0.\n                \"[('Welcome...\"\n                 ^"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Assuming you have already defined 'upwork_profiles' and 'describtion'\n",
    "\n",
    "# Step 1: Tokenize the text\n",
    "text = upwork_profiles['describtion'][5]\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Step 2: Perform POS tagging\n",
    "tag = nltk.pos_tag(tokens)\n",
    "\n",
    "pos_tree = nltk.Tree.fromstring(str(tag))\n",
    "\n",
    "# Step 2: Display the POS tree\n",
    "pos_tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1957e-3205-4cdf-b27f-5540719b35fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
