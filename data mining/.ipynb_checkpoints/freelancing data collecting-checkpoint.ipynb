{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d87eb4b-c943-4562-866b-7c2dd151f3c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <center><strong>Notebook<span style= 'color: #51FCC6'> Describtion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753d54c-1fd0-441c-b663-98ca78298128",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59118b7-50cf-4738-8e35-cd9de6b6e46c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b08419ad-46bc-42a6-a678-356c38c435fe",
   "metadata": {},
   "source": [
    "## <center><strong>Importing<span style= 'color: #48E0DC'> Packeges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfca499a-0b6e-42a6-9901-a25b403a1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "import inspect\n",
    "import warnings\n",
    "import requests\n",
    "import itertools\n",
    "import cloudscraper\n",
    "import numpy                         as np\n",
    "import pandas                        as pd\n",
    "import seaborn                       as sns\n",
    "import matplotlib.pyplot             as plt\n",
    "\n",
    "from itertools                       import count\n",
    "from bs4                             import BeautifulSoup\n",
    "from selenium                        import webdriver\n",
    "from selenium.webdriver.common.by    import By\n",
    "from selenium.webdriver.common.keys  import Keys\n",
    "from fake_useragent                  import UserAgent\n",
    "from IPython.display                 import set_matplotlib_formats\n",
    "from selenium.webdriver.support.ui   import WebDriverWait\n",
    "from selenium.webdriver.support      import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837b8e77-3b20-4c92-8619-434de6cedf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "\n",
    "MAX_PAGES        :int   = 10\n",
    "COLORS           :list  = ['#51fcc6', '#48e0dc', '#5cd3f7', '#4895e0', '#517afc']\n",
    "NUMERICS         :list  = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64',\n",
    "                           'uint16', 'uint32', 'uint64']\n",
    "\n",
    "data_jobs_titles :list  = ['Data entry', 'Data Engineering',\n",
    "                           'Data scientist', 'Data Analyst',\n",
    "                           'Machine Learning']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3e9fc-3746-4f76-be83-00f2b453be34",
   "metadata": {},
   "source": [
    "## <center><strong>Setting up the<span style= 'color: #5CD3F7'> Web scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd35b8e-8c12-4e99-8819-4c6e338c3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url: str) -> BeautifulSoup:\n",
    "\n",
    "    scraper = cloudscraper.create_scraper(delay= 10,browser= {\n",
    "        'browser': 'chrome',\n",
    "        'platform': 'windows',\n",
    "        'desktop': True,\n",
    "        'mobile': False}) \n",
    "    \n",
    "    content = scraper.get(url).text\n",
    "    soup    = BeautifulSoup(content)\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3908558f-1fe9-4c88-af63-731658ee2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upwork scraper\n",
    "def upwork_scraper(job_title : str,\n",
    "                   page      : int) -> list:\n",
    "\n",
    "    url         : str  = f'https://www.upwork.com/search/profiles/?page={page}&q={job_title}'\n",
    "    soup        : str  = scrape_page(url)\n",
    "    loaded_jobs : list = soup.find_all('div', class_= 'up-card-section up-card-hover')\n",
    "\n",
    "    return  loaded_jobs\n",
    "\n",
    "\n",
    "# Guru scraper\n",
    "def guru_scraper(job_title : str,\n",
    "                 page      : int) -> list:\n",
    "\n",
    "    url         : str  = f'https://www.guru.com/d/freelancers/skill/{job_title}/pg/{page}/'\n",
    "    soup        : str  = scrape_page(url)\n",
    "    loaded_jobs : list = soup.find_all('div', class_= 'record record--avatarCheck findGuruRecord')\n",
    "    loaded_page : int  = int(soup.find('li', class_= 'active').find('a').text)\n",
    "    \n",
    "    if loaded_page != page:\n",
    "        loaded_jobs = []\n",
    "\n",
    "    return loaded_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788705f-2f61-4a5c-ad84-ea24f56bccdb",
   "metadata": {},
   "source": [
    "Now we will try to calculate how much did each scraper take to collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0669639d-0404-4d98-aecf-1a626addee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.86 s ± 376 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "925 ms ± 121 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit upwork_scraper('Data analytics', 1)\n",
    "%timeit guru_scraper('Data analytics', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994cfd62-4513-4cd0-bea7-40c4638debc0",
   "metadata": {},
   "source": [
    "## <center><strong>Collecting the Websites <span style = 'color: #4895e0'> HTML</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11593e37-e845-41f0-b749-5f6c8d7a0914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_name(var):\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    return [var_name for var_name, var_val in callers_local_vars if var_val is var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b219d160-162a-4860-9116-60302878d539",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started scraping Guru data.\n",
      "Finished loading Data entry jobs data from Guru\n",
      "Finished loading Data Engineering jobs data from Guru\n",
      "Finished loading Data scientist jobs data from Guru\n",
      "Finished loading Data Analyst jobs data from Guru\n",
      "Finished loading Machine Learning jobs data from Guru\n",
      "\n",
      "Started scraping Upwork data.\n",
      "Finished loading Data entry jobs data from Upwork\n",
      "Finished loading Data Engineering jobs data from Upwork\n",
      "Finished loading Data scientist jobs data from Upwork\n",
      "Finished loading Data Analyst jobs data from Upwork\n",
      "Finished loading Machine Learning jobs data from Upwork\n"
     ]
    }
   ],
   "source": [
    "soups : dict = {'jobs_soups'     : [],\n",
    "                'data_job_title' : [],\n",
    "                'platform'       : []}\n",
    "\n",
    "for scraper in [guru_scraper, upwork_scraper]:\n",
    "    scraper_name      : str  = retrieve_name(scraper)[0].split('_')[0].title()\n",
    "    print(f'\\nStarted scraping {scraper_name} data.')\n",
    "    \n",
    "    for job_title in data_jobs_titles:\n",
    "\n",
    "        concated_jobs : list = []\n",
    "\n",
    "        for i in count(0):\n",
    "            page      : int  = i + 1\n",
    "            jobs      : list = scraper(job_title, page)\n",
    "\n",
    "            if (len(jobs) == 0) or (page >= MAX_PAGES):\n",
    "                break\n",
    "\n",
    "            for job in jobs:\n",
    "                concated_jobs.append(job)\n",
    "\n",
    "\n",
    "        print(f'Finished loading {job_title} jobs data from {scraper_name}')\n",
    "        \n",
    "        soups['jobs_soups']     .append(concated_jobs)\n",
    "        soups['data_job_title'] .append(job_title)\n",
    "        soups['platform']       .append(scraper_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00632aa1-9b7a-4e33-ab44-962f17b39b0b",
   "metadata": {},
   "source": [
    "## <center><strong> Collecting <span style= 'color: #517afc'>Cards</span> Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3dddfc02-f25f-4f61-9f26-6b13056422bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "guru_df   = stacked_df[stacked_df['platform'] == 'Guru'].reset_index()\n",
    "upwork_df = stacked_df[stacked_df['platform'] == 'Upwork'].reset_index()\n",
    "\n",
    "guru_df['describtion']     = None\n",
    "guru_df['earnings_amount'] = None\n",
    "guru_df['feedback']        = None\n",
    "guru_df['name']            = None\n",
    "guru_df['job_title']       = None\n",
    "guru_df['addresse']        = None\n",
    "guru_df['hour_rate']       = None\n",
    "guru_df['minimum_pay']     = None\n",
    "guru_df['skills']          = None\n",
    "\n",
    "upwork_df['describtion']          = None\n",
    "upwork_df['earnings_amount']      = None\n",
    "upwork_df['feedback']             = None\n",
    "upwork_df['name']                 = None\n",
    "upwork_df['job_title']            = None\n",
    "upwork_df['country']              = None\n",
    "upwork_df['hour_rate']            = None\n",
    "upwork_df['consultations_offers'] = None\n",
    "upwork_df['skills']               = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe538ed-36ee-4147-aeac-03dcca50ad96",
   "metadata": {},
   "source": [
    "#### **Loading Guru data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f86c767-78f2-46d0-8ddb-3b80bfcecacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, jobs in enumerate(guru_df['jobs_soups']):\n",
    "    \n",
    "    describtions     : list = []\n",
    "    earnings_amounts : list = []\n",
    "    feedbacks        : list = []\n",
    "    names            : list = []\n",
    "    job_titles       : list = []\n",
    "    addresses        : list = []\n",
    "    hour_rates       : list = []\n",
    "    minimum_pays     : list = []\n",
    "    skills           : list = []\n",
    "\n",
    "    for job in jobs:\n",
    "\n",
    "        try:      describtions     .append(job.find('p', 'serviceListing__desc').text.strip())\n",
    "        except:   describtions     .append(np.nan)\n",
    "\n",
    "        # Earnings per year\n",
    "        try:      earnings_amounts .append(job.find('span', 'earnings__amount').text.strip())\n",
    "        except:   earnings_amounts .append(np.nan)\n",
    "\n",
    "        # Feedback\n",
    "        try:      feedbacks        .append(job.find('span', 'freelancerAvatar__feedback').text.strip())\n",
    "        except:   feedbacks        .append(np.nan)\n",
    "\n",
    "        # Name\n",
    "        try:      names            .append(job.find('h3', 'freelancerAvatar__screenName').find('a').text.strip())\n",
    "        except:   names            .append(np.nan)\n",
    "\n",
    "        # Job title\n",
    "        try:      job_titles       .append(job.find('h2', 'serviceListing__title serviceListing__title--dark').find('a').text.strip())\n",
    "        except:   job_titles       .append(np.nan)\n",
    "\n",
    "        # Addresse\n",
    "        try:      addresses        .append(job.find('span', 'freelancerAvatar__location')['title'].strip())\n",
    "        except:   addresses        .append(np.nan)\n",
    "        \n",
    "        # Hour rate\n",
    "        try:      hour_rates       .append(job.find('p', 'serviceListing__rates').text.split('.')[0].strip())\n",
    "        except:   hour_rates       .append(np.nan)\n",
    "        \n",
    "        # Minimum pays\n",
    "        try:      minimum_pays     .append(job.find('p', 'serviceListing__rates').text.split('·')[-1].strip())\n",
    "        except:   minimum_pays     .append(np.nan)\n",
    "\n",
    "        # Skills\n",
    "        try:\n",
    "            skills_temp = job.find_all('a', 'skillsList__skill skillsList__skill--hasHover')\n",
    "            skills                 .append([skill.text.strip() for skill in skills_temp])\n",
    "            \n",
    "        except:   skills           .append(np.nan)\n",
    "        \n",
    "    # Now we are going to convert list into tuples.\n",
    "    guru_df['describtion']     [i] = tuple(describtions)\n",
    "    guru_df['earnings_amount'] [i] = tuple(earnings_amounts)\n",
    "    guru_df['feedback']        [i] = tuple(feedbacks)\n",
    "    guru_df['name']            [i] = tuple(names)\n",
    "    guru_df['job_title']       [i] = tuple(job_titles)\n",
    "    guru_df['addresse']        [i] = tuple(addresses)\n",
    "    guru_df['hour_rate']       [i] = tuple(hour_rates)\n",
    "    guru_df['minimum_pay']     [i] = tuple(minimum_pays)\n",
    "    guru_df['skills']          [i] = tuple(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0ad81-d278-4b04-95b3-7bb7c585d41d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Loading Upwork data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bb3ba47-4b3a-471d-a402-a9505773b6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, jobs in enumerate(upwork_df['jobs_soups']):\n",
    "    \n",
    "    describtions         : list = []\n",
    "    earnings_amounts     : list = []\n",
    "    feedbacks            : list = []\n",
    "    names                : list = []\n",
    "    job_titles           : list = []\n",
    "    countries            : list = []\n",
    "    hour_rates           : list = []\n",
    "    skills               : list = []\n",
    "    consultations_offers : list = []\n",
    "    \n",
    "\n",
    "    for job in jobs:\n",
    "\n",
    "        try:      describtions          .append(job.find('div', 'up-line-clamp-v2 clamped').text.strip())\n",
    "        except:   describtions          .append(np.nan)\n",
    "\n",
    "        # Earnings per year\n",
    "        try:      earnings_amounts      .append(job.find('span',attrs= {'data-test', 'earned-amount-formatted'}).text.strip())\n",
    "        except:   earnings_amounts      .append(np.nan)\n",
    "\n",
    "        # Feedback\n",
    "        try:      feedbacks             .append(job.find('span', 'up-job-success-text').text.split('%')[0].strip())\n",
    "        except:   feedbacks             .append(np.nan)\n",
    "\n",
    "        # Name\n",
    "        try:      names                 .append(job.find('div', 'identity-name').text.strip())\n",
    "        except:   names                 .append(np.nan)\n",
    "\n",
    "        # Job title\n",
    "        try:      job_titles            .append(job.find('p', 'my-0 freelancer-title').find('strong').text.strip())\n",
    "        except:   job_titles            .append(np.nan)\n",
    "\n",
    "        # Country\n",
    "        try:      countries             .append(job.find('span', attrs= {'itemprop': 'country-name'}).text.strip())\n",
    "        except:   countries             .append(np.nan)\n",
    "        \n",
    "        # Hour rate\n",
    "        try:      hour_rates            .append(job.find('div', 'grid-col-1 grid-col-sm-1 justify-self-start nowrap').find('strong').text.strip())\n",
    "        except:   hour_rates            .append(np.nan)\n",
    "        \n",
    "        # Offers consultations\n",
    "        try:      consultations_offers  .append(job.find('div', 'up-skill-badge up-badge up-badge-highlight up-badge-rounded-inverse').text.strip())\n",
    "        except:   consultations_offers  .append('Doesn\\'t offer consultations')\n",
    "        \n",
    "        # Skills\n",
    "        try:\n",
    "            skills_temp = job.find_all('div', 'up-skill-badge')\n",
    "            skills                 .append([skill.text.strip() for skill in skills_temp])\n",
    "            \n",
    "        except:   skills           .append(np.nan)\n",
    "        \n",
    "    # Now we are going to convert list into tuples.\n",
    "    upwork_df['describtion']          [i] = tuple(describtions)\n",
    "    upwork_df['earnings_amount']      [i] = tuple(earnings_amounts)\n",
    "    upwork_df['feedback']             [i] = tuple(feedbacks)\n",
    "    upwork_df['name']                 [i] = tuple(names)\n",
    "    upwork_df['job_title']            [i] = tuple(job_titles)\n",
    "    upwork_df['country']              [i] = tuple(countries)\n",
    "    upwork_df['hour_rate']            [i] = tuple(hour_rates)\n",
    "    upwork_df['consultations_offers'] [i] = tuple(consultations_offers)\n",
    "    upwork_df['skills']               [i] = tuple(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "292c8621-4b47-4073-8c3a-c067aa5a8cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>jobs_soups</th>\n",
       "      <th>job_title</th>\n",
       "      <th>platform</th>\n",
       "      <th>describtion</th>\n",
       "      <th>earnings_amount</th>\n",
       "      <th>feedback</th>\n",
       "      <th>name</th>\n",
       "      <th>addresse</th>\n",
       "      <th>hour_rate</th>\n",
       "      <th>minimum_pay</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[\\n, [\\n, &lt;input :value=\"1769804\" aria-label=...</td>\n",
       "      <td>(Data Entry | Data Processing, Data Entry, Dat...</td>\n",
       "      <td>Guru</td>\n",
       "      <td>(We are Data Entry Specialists ‍ who offer hel...</td>\n",
       "      <td>(58,742, 42,580, 27,100, 22,010, 17,289, 21,99...</td>\n",
       "      <td>(100%, 100%, 100%, 99.5%, 100%, 100%, 100%, 10...</td>\n",
       "      <td>(Tinkogroup, BR Solutions Pvt. Ltd.- App exper...</td>\n",
       "      <td>(Poltava, Poltavs'ka Oblast', Ukraine, New Del...</td>\n",
       "      <td>($10/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "      <td>(Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>([Data Entry, Admin Support, Copy and Paste, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[\\n, [\\n, &lt;input :value=\"538436\" aria-label=\"...</td>\n",
       "      <td>(Data Engineering Solutions, Enterprise Data E...</td>\n",
       "      <td>Guru</td>\n",
       "      <td>(Our engineers help you unleash the power of b...</td>\n",
       "      <td>(279,940, 95,587, 34,078, 20,673, ID Verified,...</td>\n",
       "      <td>(100%, 100%, 100%, 100%, nan, nan, nan, nan, n...</td>\n",
       "      <td>(NIX-agency, GJB Enterprise Solutions, Colan I...</td>\n",
       "      <td>(Kfar Saba, Tel Aviv, Israel, Belton, Texas, U...</td>\n",
       "      <td>($45/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "      <td>(Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>([Data Engineering, Data Architecture, Data Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[\\n, [\\n, &lt;input :value=\"2712307\" aria-label=...</td>\n",
       "      <td>(Data Scientist, Data Scientist, Data scientis...</td>\n",
       "      <td>Guru</td>\n",
       "      <td>(Hello, My name is Arsalan Younus and I am ver...</td>\n",
       "      <td>(42,312, 7,396, 6,999, 4,220, 10,960, 30, nan,...</td>\n",
       "      <td>(100%, 100%, 100%, 100%, 91.3%, 100%, nan, nan...</td>\n",
       "      <td>(Arsalan Younus, Kevin S. R., Tuan Cuong Dinh,...</td>\n",
       "      <td>(Faisalabad, Punjab, Pakistan, Stanford, Calif...</td>\n",
       "      <td>($25/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "      <td>(Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>([Data Scientist, Analytics, Artificial Neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[\\n, [\\n, &lt;input :value=\"3709060\" aria-label=...</td>\n",
       "      <td>(Data analyst, data analyst, excel dashboard, ...</td>\n",
       "      <td>Guru</td>\n",
       "      <td>(Experienced in working with MS word, excel, p...</td>\n",
       "      <td>(2,436, 10,661, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>(100%, 98.2%, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>(Shah Kabeer, Speedy Websites &amp; Graphics Solut...</td>\n",
       "      <td>(Havelian, North-West Frontier, Pakistan, Bhak...</td>\n",
       "      <td>($5/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>(Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>([Data Analyst, Data Collection, Data Entry, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[\\n, [\\n, &lt;input :value=\"3587209\" aria-label=...</td>\n",
       "      <td>(AI, Machine Learning, ChatGPT Dev, IOT &amp; Gene...</td>\n",
       "      <td>Guru</td>\n",
       "      <td>(I am a Machine Learning Engineer with 10+ yea...</td>\n",
       "      <td>(240,221, 65,663, 95,587, 62,284, 35,000, 46,7...</td>\n",
       "      <td>(99.2%, 100%, 100%, 100%, 100%, 100%, 100%, 10...</td>\n",
       "      <td>(Steve Y., Vnnovate Solutions, GJB Enterprise ...</td>\n",
       "      <td>(Lakeville, Minnesota, United States, Ahmedaba...</td>\n",
       "      <td>($70/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "      <td>(Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>([Machine Learning, Algorithms, Analytics, Art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         jobs_soups  \\\n",
       "0      0  [[\\n, [\\n, <input :value=\"1769804\" aria-label=...   \n",
       "1      1  [[\\n, [\\n, <input :value=\"538436\" aria-label=\"...   \n",
       "2      2  [[\\n, [\\n, <input :value=\"2712307\" aria-label=...   \n",
       "3      3  [[\\n, [\\n, <input :value=\"3709060\" aria-label=...   \n",
       "4      4  [[\\n, [\\n, <input :value=\"3587209\" aria-label=...   \n",
       "\n",
       "                                           job_title platform  \\\n",
       "0  (Data Entry | Data Processing, Data Entry, Dat...     Guru   \n",
       "1  (Data Engineering Solutions, Enterprise Data E...     Guru   \n",
       "2  (Data Scientist, Data Scientist, Data scientis...     Guru   \n",
       "3  (Data analyst, data analyst, excel dashboard, ...     Guru   \n",
       "4  (AI, Machine Learning, ChatGPT Dev, IOT & Gene...     Guru   \n",
       "\n",
       "                                         describtion  \\\n",
       "0  (We are Data Entry Specialists ‍ who offer hel...   \n",
       "1  (Our engineers help you unleash the power of b...   \n",
       "2  (Hello, My name is Arsalan Younus and I am ver...   \n",
       "3  (Experienced in working with MS word, excel, p...   \n",
       "4  (I am a Machine Learning Engineer with 10+ yea...   \n",
       "\n",
       "                                     earnings_amount  \\\n",
       "0  (58,742, 42,580, 27,100, 22,010, 17,289, 21,99...   \n",
       "1  (279,940, 95,587, 34,078, 20,673, ID Verified,...   \n",
       "2  (42,312, 7,396, 6,999, 4,220, 10,960, 30, nan,...   \n",
       "3  (2,436, 10,661, nan, nan, nan, nan, nan, nan, ...   \n",
       "4  (240,221, 65,663, 95,587, 62,284, 35,000, 46,7...   \n",
       "\n",
       "                                            feedback  \\\n",
       "0  (100%, 100%, 100%, 99.5%, 100%, 100%, 100%, 10...   \n",
       "1  (100%, 100%, 100%, 100%, nan, nan, nan, nan, n...   \n",
       "2  (100%, 100%, 100%, 100%, 91.3%, 100%, nan, nan...   \n",
       "3  (100%, 98.2%, nan, nan, nan, nan, nan, nan, na...   \n",
       "4  (99.2%, 100%, 100%, 100%, 100%, 100%, 100%, 10...   \n",
       "\n",
       "                                                name  \\\n",
       "0  (Tinkogroup, BR Solutions Pvt. Ltd.- App exper...   \n",
       "1  (NIX-agency, GJB Enterprise Solutions, Colan I...   \n",
       "2  (Arsalan Younus, Kevin S. R., Tuan Cuong Dinh,...   \n",
       "3  (Shah Kabeer, Speedy Websites & Graphics Solut...   \n",
       "4  (Steve Y., Vnnovate Solutions, GJB Enterprise ...   \n",
       "\n",
       "                                            addresse  \\\n",
       "0  (Poltava, Poltavs'ka Oblast', Ukraine, New Del...   \n",
       "1  (Kfar Saba, Tel Aviv, Israel, Belton, Texas, U...   \n",
       "2  (Faisalabad, Punjab, Pakistan, Stanford, Calif...   \n",
       "3  (Havelian, North-West Frontier, Pakistan, Bhak...   \n",
       "4  (Lakeville, Minnesota, United States, Ahmedaba...   \n",
       "\n",
       "                                           hour_rate  \\\n",
       "0  ($10/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...   \n",
       "1  ($45/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...   \n",
       "2  ($25/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...   \n",
       "3  ($5/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "4  ($70/hr\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\...   \n",
       "\n",
       "                                         minimum_pay  \\\n",
       "0  (Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "1  (Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "2  (Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "3  (Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "4  (Starting at\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "\n",
       "                                              skills  \n",
       "0  ([Data Entry, Admin Support, Copy and Paste, C...  \n",
       "1  ([Data Engineering, Data Architecture, Data Ma...  \n",
       "2  ([Data Scientist, Analytics, Artificial Neural...  \n",
       "3  ([Data Analyst, Data Collection, Data Entry, D...  \n",
       "4  ([Machine Learning, Algorithms, Analytics, Art...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guru_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba2f2d-ec01-47a4-b0c2-403f9efd2e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
