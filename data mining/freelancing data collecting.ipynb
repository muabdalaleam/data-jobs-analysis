{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d87eb4b-c943-4562-866b-7c2dd151f3c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <center><strong>Notebook<span style= \"color: #51FCC6\"> Describtion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753d54c-1fd0-441c-b663-98ca78298128",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59118b7-50cf-4738-8e35-cd9de6b6e46c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b08419ad-46bc-42a6-a678-356c38c435fe",
   "metadata": {},
   "source": [
    "## <center><strong>Importing<span style= \"color: #48E0DC\"> Packeges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfca499a-0b6e-42a6-9901-a25b403a1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import count\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium.webdriver.common.by import By\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837b8e77-3b20-4c92-8619-434de6cedf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FreeComp\\AppData\\Local\\Temp\\ipykernel_3640\\2138414856.py:8: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('pdf', 'svg')\n"
     ]
    }
   ],
   "source": [
    "COLORS = [\"#51fcc6\", \"#48e0dc\", \"#5cd3f7\", \"#4895e0\", \"#517afc\"]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "NUMERICS = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64',\n",
    "            'uint16', 'uint32', 'uint64']\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3e9fc-3746-4f76-be83-00f2b453be34",
   "metadata": {},
   "source": [
    "## <center><strong>Setting up the<span style= \"color: #5CD3F7\"> Web scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd35b8e-8c12-4e99-8819-4c6e338c3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jobs_titles = [\"data-entry\", \"data-processing\", \"data-engineering\",\n",
    "                    \"data-science\", \"data-analytics\", \"data-visualization\"]\n",
    "\n",
    "guru_data_jobs_titles = [\"data-analytics\", \"machine-learning\", \"data-visualization\"]\n",
    "\n",
    "\n",
    "upwork_types = [\"profiles\", \"jobs\", \"services\"]\n",
    "freelancer_types = [\"users\", \"projects\"]\n",
    "peapleperhour_types = [\"hire-freelancers\", \"freelance-jobs\", \"services\"]\n",
    "guru_service_types = [\"freelancers\", \"jobs\"]\n",
    "\n",
    "\n",
    "def scrape_page(url: str) -> BeautifulSoup:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    # Wait until the page is fully loaded\n",
    "    wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "    \n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    return BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ff1bdf-99da-46f6-ab1e-b41c542daaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `type` param indicates what is the nature of the job is it hiring freelancers \n",
    "# or paying services or othr thing based on the platform.\n",
    "\n",
    "def upwork_scraper(page, job_title, type):\n",
    "\n",
    "    global upwork_url\n",
    "\n",
    "    if  type == 'services':\n",
    "\n",
    "        upwork_url =  f\"https://www.upwork.com/services/search?nbs=1&q={job_title}\"\n",
    "\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(upwork_url)\n",
    "\n",
    "        if page > 1:\n",
    "            for i in ragne(page):\n",
    "                \n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.up-btn.up-btn-default.mx-0.load-more-btn.nuxt-link-active')))\n",
    "                element.click()\n",
    "                \n",
    "                time.sleep(1)\n",
    "\n",
    "        html = driver.page_source\n",
    "        driver.quit()\n",
    "        \n",
    "        return  html\n",
    "\n",
    "    elif type == \"profiles\" or type == \"jobs\":\n",
    "        \n",
    "        upwork_url = f\"https://www.upwork.com/search/{type}/?page={page}&q={job_title}&user_pref=1\"\n",
    "        \n",
    "        return scrape_page(upwork_url)\n",
    "\n",
    "\n",
    "def guru_scraper(page, job_title, type):\n",
    "\n",
    "    global guru_url\n",
    "    guru_url = f\"https://www.guru.com/d/{type}/c/programming-development/sc/math-algorithms-analytics/ssc/{job_title}/pg/{page}/\"\n",
    "\n",
    "    return scrape_page(guru_url)\n",
    "\n",
    "\n",
    "def fivver_scraper(page, job_title):\n",
    "\n",
    "    global fivver_url\n",
    "    fivver_url = f\"https://www.fiverr.com/categories/data/{job_title}?source=pagination&page={page}\"\n",
    "\n",
    "    return scrape_page(fivver_url)\n",
    "\n",
    "\n",
    "def peopleperhour_scraper(page, job_title, type):\n",
    "\n",
    "    global peopleperhour_url\n",
    "\n",
    "    if type == \"hire-freelancers\":\n",
    "        peopleperhour_url = f\"https://www.peopleperhour.com/hire-freelancers/{job_title.replace('-', '+')}?page={page}&ref=search\"\n",
    "\n",
    "    else:\n",
    "        peopleperhour_url = f\"https://www.peopleperhour.com/{type}-{job_title.replace('-', '+')}\"\n",
    "\n",
    "    return  scrape_page(peopleperhour_url)\n",
    "\n",
    "# We will not analyze requested jobs data in freelancer.com becuase it's search feature \n",
    "# isn't accurate with the it.\n",
    "\n",
    "def freelancer_scraper(page, job_title, type):\n",
    "\n",
    "    global freelancer_url\n",
    "    freelancer_url = f\"https://www.freelancer.com/search/{type}?q={job_title.replace('-', '%20')}&page={page}\"\n",
    "    \n",
    "    return scrape_page(freelancer_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788705f-2f61-4a5c-ad84-ea24f56bccdb",
   "metadata": {},
   "source": [
    "Now we will try to calculate how much did each scraper take to collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0141299-f023-4a63-8e8b-52320c0b3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_variable_name = lambda var: [name for name in globals() if globals()[name] is var][0]\n",
    "\n",
    "def get_runtime(func, *args, **kwargs):\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    output = func(*args, **kwargs)\n",
    "    t2 = time.perf_counter()\n",
    "\n",
    "    run_time = t2 - t1\n",
    "\n",
    "    print(\"{} took about {:.2f}s to run.\\n\".format(\n",
    "        get_variable_name(func).replace(\"_\", \" \").title(), run_time))\n",
    "\n",
    "    return  output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619ad86-0c3f-4288-a5cb-8b3591513b88",
   "metadata": {},
   "source": [
    "Now we will just try to scrape **only one page** from each scraper *(temporary action)* to just test the data extractors with<br>\n",
    "more efficient way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994cfd62-4513-4cd0-bea7-40c4638debc0",
   "metadata": {},
   "source": [
    "## <center><strong>Extracting jobs <span style = \"color: #4895e0\"> Links</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b219d160-162a-4860-9116-60302878d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = {\"soup_name\": [],\n",
    "         \"soup_job_type\": [],\n",
    "         \"soup_job_title\": [],\n",
    "         \"soup_page\":  [],\n",
    "         \"soup\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d79a77b-f579-4750-984a-599fa9df13d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If the job type is services in upwork the pages paremeter will refer to how many pages \n",
    "# will render at once while the other scrapers will render the spesfic spesfied page only.\n",
    "\n",
    "for i in count(0):\n",
    "\n",
    "    global orgnaize_data_in_dict\n",
    "    page = i + 1\n",
    "\n",
    "    for data_job_title in data_jobs_titles:\n",
    "            # for job_type in \n",
    "        lines = [f'peopleperhour_html = peopleperhour_scraper({page}, {data_job_title}, peopleperhour_types)',\n",
    "                 f'fivver_html = fivver_scraper({page}, {data_job_title})',\n",
    "                 f'freelancer_html = freelancer_scraper({page}, {data_job_title}, freelancer_types)',\n",
    "                 f'upwork_html = upwork_scraper({page}, {data_job_title}, upwork_types)']\n",
    "\n",
    "        for line_idx, line in enumerate(lines):\n",
    "            \n",
    "            equall_sign_idx = line.find('=')\n",
    "            \n",
    "            def orgnaize_data_in_dict():\n",
    "                soups[\"soup_job_title\"].append(data_job_title)\n",
    "                soups[\"soup_name\"].append(line[:equall_sign_idx])\n",
    "                soups[\"soup_page\"].append(page)\n",
    "                soups[\"soup\"].append(exec(line[:equall_sign_idx]))\n",
    "                soups[\"soup_job_type\"].append(job_type)\n",
    "\n",
    "            try:\n",
    "                if i == 0:\n",
    "                    exec(line)\n",
    "                    orgnaize_data_in_dict()\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "\n",
    "                del lines[line_idx]\n",
    "                if len(lines) < 1:\n",
    "\n",
    "                    print(\"Finished ...\")\n",
    "                    break\n",
    "    \n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec6ccf-4765-43c8-bd23-9c6ea46a781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in count(0):\n",
    "\n",
    "    page = i + 1\n",
    "    \n",
    "    for  guru_data_job_title in guru_data_jobs_titles:\n",
    "        \n",
    "        line = f'guru_html = guru_scraper({page}, {guru_data_job_title}, guru_type_placeholder)'\n",
    "\n",
    "            try:\n",
    "                if i == 0:\n",
    "                    exec(line)\n",
    "\n",
    "                else:\n",
    "                    equall_sign_idx = line.find('=')\n",
    "                    temp_text = f\"\"\"{line[:equall_sign_idx]} = str({line[:equall_sign_idx - 1]}.body) + \\'\\\\n<b>SEPARATOR\\\\n</b>\\' + str({line[equall_sign_idx + 2:]}.body)\"\"\"\n",
    "                    exec(temp_text)\n",
    "\n",
    "            except Exception as e:\n",
    "\n",
    "                del lines[line_idx]\n",
    "                if len(lines) < 1:\n",
    "\n",
    "                    print(\"Finished ...\")\n",
    "                    break\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22df0a0-010d-445b-96c5-b0dbb503ffd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soup_name</th>\n",
       "      <th>soup_url</th>\n",
       "      <th>soup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [soup_name, soup_url, soup]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69053b64-427f-4286-b1f4-dd5d1db4ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pages = [upwork_html,\n",
    "             fivver_html,\n",
    "             guru_html,\n",
    "             peopleperhour_html,\n",
    "             freelancer_html]\n",
    "\n",
    "soups = {\"soup_name\": [],\n",
    "         \"soup_url\": [],\n",
    "         \"soup\": []}\n",
    "\n",
    "for page in test_pages:\n",
    "\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    soups[\"soup\"].append(soup)\n",
    "    soups[\"soup_name\"].append(get_variable_name(page).replace(\"html\",\n",
    "                                                              \"soup\"))\n",
    "    \n",
    "    soups[\"soup_url\"].append(eval(get_variable_name(page)[:-5] + \"_url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7ce831-bd81-4a23-b771-30457a6a1388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the title of each page to check if it's loaded correctly.\n",
      "\n",
      "-\t Freelance Data-analytics Jobs - Upwork\n",
      "-\t Data Analytics Services Online | Fiverr\n",
      "-\t Machine Learning Freelance Jobs Online - Guru\n",
      "-\t Get Data Analytics Offers & Services | PeoplePerHour\n",
      "-\t Users Jobs, Employment | Freelancer\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing the title of each page to check if it's loaded correctly.\\n\")\n",
    "\n",
    "for soup in soups[\"soup\"]:\n",
    "    print(\"-\\t\", soup.title.text.replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "\n",
    "soups = pd.DataFrame(soups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db860af4-9005-4f07-8bfa-cab4cdb3aa87",
   "metadata": {},
   "source": [
    "Looks like everything is working as expected now let's start reel work by extracting the HTML tags data from the scraped<br>\n",
    "pages.<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac5af7-1f3f-44a7-b93b-778e70096067",
   "metadata": {},
   "source": [
    "But we will need to collect the data from each one of those pages with unique way further more we need to optimize the<br>\n",
    "data extractor to collect the data from other pages from the same site like \"jobs\" site and \"profiles\" sites on upwork.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1daedfc1-75bc-45e0-9045-43107fac0999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soups[soups[\"soup_name\"] == 'peopleperhour_soup'][\"soup\"].values[0].find_all(\"a\", attrs= {\"class\": \"card__title-wrapper⤍FreelancerCard⤚2-NWk\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dfb3b7e-ed6c-49db-a27b-05e963d689ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cards_links(soup_name, tag, link_template,\n",
    "                    link_attr, tag_class, attr= \"class\") -> list:\n",
    "\n",
    "    soup = soups[soups[\"soup_name\"] == soup_name][\"soup\"].values[0]\n",
    "                        \n",
    "    cards = soup.find_all(tag, attrs= {attr: tag_class})\n",
    "    cards_ids = []\n",
    "\n",
    "    if link_attr != \"\":\n",
    "\n",
    "        for card in cards:\n",
    "\n",
    "            card_id = link_template.replace(\"###\", card[link_attr])\n",
    "\n",
    "            if len(card_id) > len(link_template):\n",
    "                cards_ids.append(card_id)\n",
    "\n",
    "        return  cards_ids\n",
    "        \n",
    "    else:\n",
    "        return  cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "710987e9-6eb6-47cd-a8ec-8d1777445501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't collect guru data this wat becuase it has slightly deffrint case in terms\n",
    "# of collecting the jobs URLs\n",
    "\n",
    "## --------------------------Upwork--------------------------\n",
    "upwork_gigs_links = get_cards_links('upwork_soup', 'a', 'https://upwork.com###', 'href',\n",
    "                                        'up-n-link project-tile up-card m-0 p-0 up-card-section up-card-hover project-tile_flexible')\n",
    "\n",
    "upwork_profiles_links = get_cards_links('upwork_soup', 'div', 'https://www.upwork.com/search/profiles/?profile=###', 'data-test-key',\n",
    "                                         'up-card-section up-card-hover')\n",
    "\n",
    "upwork_jobs_parents = get_cards_links('upwork_soup', 'h3', 'https://www.upwork.com###', '', 'my-0 p-sm-right job-tile-title')\n",
    "upwork_jobs_links = []\n",
    "\n",
    "for parent in upwork_jobs_parents:\n",
    "    upwork_jobs_links.append(\"https://www.upwork.com\" + parent.find('a', class_= \"up-n-link\")['href'])\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## --------------------------Fivver--------------------------\n",
    "fivver_gigs_links = get_cards_links('fivver_soup', 'a', 'https://www.fiverr.com###', 'href', 'tbody-5 p-t-4 YLycza2 u9KHmsf')\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## ---------------------People per hour----------------------\n",
    "pph_services_links = get_cards_links(\"peopleperhour_soup\", \"a\", \"https://www.peopleperhour.com###\", \"href\", \n",
    "                                     \"card__title-wrapper⤍FreelancerCard⤚2-NWk\")\n",
    "\n",
    "pph_freelancers_links = get_cards_links(\"peopleperhour_soup\", \"a\", \"https://www.peopleperhour.com###\", \"href\",\n",
    "                                        \"card__title-wrapper⤍FreelancerCard⤚2-NWk\")\n",
    "\n",
    "pph_jobs_links = get_cards_links(\"peopleperhour_soup\", \"a\", \"https://www.peopleperhour.com###\", \"href\",\n",
    "                                 \"item__url⤍ListItem⤚20ULx\")\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## ------------------------Guru------------------------------\n",
    "guru_cards_parents_profiles = get_cards_links(\"guru_soup\", \"h2\", \"https://guru.com###\", \"\",\n",
    "                                              \"jobRecord__title jobRecord__title--changeVisited\")\n",
    "\n",
    "guru_cards_parents_jobs = get_cards_links(\"guru_soup\", \"h2\", \"https://guru.com###\", \"\",\n",
    "                                          \"jobRecord__title jobRecord__title--changeVisited\")\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## ----------------------Freelancer---------------------------\n",
    "freelancer_jobs_links = get_cards_links(\"freelancer_soup\", \"a\", \"https://www.freelancer.com###\", \"href\",\n",
    "                                        \"LinkElement ng-star-inserted\")\n",
    "\n",
    "freelancer_freelancers_links = get_cards_links(\"freelancer_soup\", \"a\", \"https://www.freelancer.com###\", \"href\",\n",
    "                                              \"LinkElement ng-star-inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04a0cdb0-c6ac-426d-a893-ce8897ccbc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freelancer_freelancers_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1caa82-9049-40af-9248-5a6dcf4d404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upwork_links(job_type: str) -> list:  \n",
    "\n",
    "    card_tag = \"a\"\n",
    "    link_template = \"https://www.upwork.com###\"\n",
    "    link_attr = \"href\"\n",
    "\n",
    "    if job_type == \"profiles\":\n",
    "\n",
    "        card_tag = \"div\"\n",
    "        card_tag_class = \"up-card-section up-card-hover\"\n",
    "        link_template = \"https://www.upwork.com/search/profiles/?q=profiles&profile=###\"\n",
    "        link_attr = \"data-test-key\"\n",
    "    \n",
    "    elif job_type == \"jobs\":\n",
    "        card_tag_class = \"up-n-link\"\n",
    "\n",
    "\n",
    "    elif job_type == \"services\":\n",
    "        card_tag_class = \"up-n-link project-tile up-card m-0 p-0 up-card-section up-card-hover project-tile_flexible\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Please input correct work type from ['profiles', 'jobs', 'services'].\")\n",
    "\n",
    "\n",
    "    soup = soups[soups[\"soup_name\"] == \"upwork_soup\"][\"soup\"][0]\n",
    "\n",
    "    cards = soup.find_all(card_tag, class_= card_tag_class)\n",
    "    cards_ids = []\n",
    "\n",
    "    for card in cards:\n",
    "        \n",
    "        card_id = link_template.replace(\"###\", card[link_attr])\n",
    "        \n",
    "        if len(card_id) > len(link_template):\n",
    "            cards_ids.append(card_id)\n",
    "\n",
    "    return  cards_ids\n",
    "\n",
    "\n",
    "def get_fivver_links() -> list:\n",
    "\n",
    "    card_tag = \"div\"\n",
    "    card_tag_class = \"basic-gig-card\"\n",
    "    link_template = \"https://www.fiverr.com###\"\n",
    "    link_attr = \"href\"\n",
    "\n",
    "    cards = soup.find_all(card_tag, class_= card_tag_class)\n",
    "    cards_ids = []\n",
    "    \n",
    "    for card in cards:\n",
    "        \n",
    "        card_id = link_template.replace(\"###\", card[link_attr])\n",
    "        \n",
    "        if len(card_id) > len(link_template):\n",
    "            cards_ids.append(card_id)\n",
    "\n",
    "    return  cards_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8189c7-4417-4b58-82f6-e1b634d4aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guru_links(job_type: str) -> list:  \n",
    "\n",
    "    soup = soups[soups[\"soup_name\"] == \"guru_soup\"][\"soup\"][2]\n",
    "    link_template = \"https://www.guru.com###\"\n",
    "\n",
    "    if job_type == \"freelancers\":\n",
    "        cards_parents = soup.find_all(\n",
    "            'h2', class_= 'serviceListing__title serviceListing__title--dark')\n",
    "\n",
    "        cards = []\n",
    "\n",
    "        for parent in cards_parents:\n",
    "            card = parent.find('a')\n",
    "            cards.append(card)\n",
    "\n",
    "    elif job_type == \"jobs\":\n",
    "        cards_parents = soup.find_all(\n",
    "            'h2', class_ = 'jobRecord__title jobRecord__title--changeVisited')\n",
    "\n",
    "        cards = []\n",
    "\n",
    "        for parent in cards_parents:\n",
    "            card = parent.find('a')\n",
    "            cards.append(card)\n",
    "\n",
    "    cards_ids = []\n",
    "\n",
    "    for card in cards:\n",
    "        card_id = link_template.replace(\"###\", card['href'])\n",
    "        cards_ids.append(card_id)\n",
    "\n",
    "    return  cards_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e58f11-9b8e-4ee0-bf80-8405af334fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_guru_links('jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd419a-7ce6-4b9f-a30b-43b66e59de47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
