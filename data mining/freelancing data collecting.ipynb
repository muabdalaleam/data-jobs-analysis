{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d87eb4b-c943-4562-866b-7c2dd151f3c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <center><strong>Notebook<span style= \"color: #51FCC6\"> Describtion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753d54c-1fd0-441c-b663-98ca78298128",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59118b7-50cf-4738-8e35-cd9de6b6e46c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b08419ad-46bc-42a6-a678-356c38c435fe",
   "metadata": {},
   "source": [
    "## <center><strong>Importing<span style= \"color: #48E0DC\"> Packeges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfca499a-0b6e-42a6-9901-a25b403a1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "import warnings\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import count\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium.webdriver.common.by import By\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837b8e77-3b20-4c92-8619-434de6cedf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FreeComp\\AppData\\Local\\Temp\\ipykernel_2904\\2138414856.py:8: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('pdf', 'svg')\n"
     ]
    }
   ],
   "source": [
    "COLORS = [\"#51fcc6\", \"#48e0dc\", \"#5cd3f7\", \"#4895e0\", \"#517afc\"]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "NUMERICS = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64',\n",
    "            'uint16', 'uint32', 'uint64']\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3e9fc-3746-4f76-be83-00f2b453be34",
   "metadata": {},
   "source": [
    "## <center><strong>Setting up the<span style= \"color: #5CD3F7\"> Web scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd35b8e-8c12-4e99-8819-4c6e338c3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jobs_titles = [\"data-entry\", \"data-processing\", \"data-engineering\",\n",
    "                    \"data-science\", \"data-analytics\", \"data-visualization\"]\n",
    "\n",
    "upwork_types = [\"profiles\", \"jobs\", \"services\"]\n",
    "freelancer_types = [\"users\", \"projects\"]\n",
    "peapleperhour_types = [\"hire-freelancers\", \"freelance-jobs\", \"services\"]\n",
    "guru_service_types = [\"freelancers\", \"jobs\"]\n",
    "\n",
    "\n",
    "def scrape_page(url: str) -> BeautifulSoup:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    # Wait until the page is fully loaded\n",
    "    wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "    \n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    return BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ff1bdf-99da-46f6-ab1e-b41c542daaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `type` param indicates what is the nature of the job is it hiring freelancers \n",
    "# or paying services or othr thing based on the platform.\n",
    "\n",
    "def upwork_scraper(page, job_title, type):\n",
    "\n",
    "    global upwork_url\n",
    "\n",
    "    if  type == 'services':\n",
    "\n",
    "        upwork_url =  f\"https://www.upwork.com/services/search?nbs=1&q={job_title}\"\n",
    "\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(upwork_url)\n",
    "\n",
    "        if page > 1:\n",
    "            for i in ragne(page):\n",
    "                \n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.up-btn.up-btn-default.mx-0.load-more-btn.nuxt-link-active')))\n",
    "                element.click()\n",
    "                \n",
    "                time.sleep(1)\n",
    "\n",
    "        html = driver.page_source\n",
    "        driver.quit()\n",
    "        \n",
    "        return  html\n",
    "\n",
    "    elif type == \"profiles\" or type == \"jobs\":\n",
    "        \n",
    "        upwork_url = f\"https://www.upwork.com/search/{type}/?page={page}&q={job_title}&user_pref=1\"\n",
    "        \n",
    "        return scrape_page(upwork_url)\n",
    "\n",
    "\n",
    "def guru_scraper(page, job_title, type):\n",
    "\n",
    "    global guru_url\n",
    "    guru_url = f\"https://www.guru.com/d/{type}/skill/{job_title}/pg/{page}/\"\n",
    "\n",
    "    return scrape_page(guru_url)\n",
    "\n",
    "\n",
    "def fivver_scraper(page, job_title):\n",
    "\n",
    "    global fivver_url\n",
    "    fivver_url = f\"https://www.fiverr.com/categories/data/{job_title}?source=pagination&page={page}\"\n",
    "\n",
    "    return scrape_page(fivver_url)\n",
    "\n",
    "\n",
    "def peopleperhour_scraper(page, job_title, type):\n",
    "\n",
    "    global peopleperhour_url\n",
    "\n",
    "    if type == \"hire-freelancers\":\n",
    "        peopleperhour_url = f\"https://www.peopleperhour.com/hire-freelancers/{job_title.replace('-', '+')}?page={page}&ref=search\"\n",
    "\n",
    "    else:\n",
    "        peopleperhour_url = f\"https://www.peopleperhour.com/{type}-{job_title.replace('-', '+')}\"\n",
    "\n",
    "    return  scrape_page(peopleperhour_url)\n",
    "\n",
    "# We will not analyze requested jobs data in freelancer.com becuase it's search feature \n",
    "# isn't accurate with the it.\n",
    "\n",
    "def freelancer_scraper(page, job_title, type):\n",
    "\n",
    "    global freelancer_url\n",
    "    freelancer_url = f\"https://www.freelancer.com/search/{type}?q={job_title.replace('-', '%20')}&page={page}\"\n",
    "    \n",
    "    return scrape_page(freelancer_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788705f-2f61-4a5c-ad84-ea24f56bccdb",
   "metadata": {},
   "source": [
    "Now we will try to calculate how much did each scraper take to collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0141299-f023-4a63-8e8b-52320c0b3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_variable_name = lambda var: [name for name in globals() if globals()[name] is var][0]\n",
    "\n",
    "def get_runtime(func, *args, **kwargs):\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    output = func(*args, **kwargs)\n",
    "    t2 = time.perf_counter()\n",
    "\n",
    "    run_time = t2 - t1\n",
    "\n",
    "    print(\"{} took about {:.2f}s to run.\\n\".format(\n",
    "        get_variable_name(func).replace(\"_\", \" \").title(), run_time))\n",
    "\n",
    "    return  output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619ad86-0c3f-4288-a5cb-8b3591513b88",
   "metadata": {},
   "source": [
    "Now we will just try to scrape **only one page** from each scraper *(temporary action)* to just test the data extractors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994cfd62-4513-4cd0-bea7-40c4638debc0",
   "metadata": {},
   "source": [
    "## <center><strong>Extracting jobs <span style = \"color: #4895e0\"> Links</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea921a58-c509-49d6-b8c7-7c52c96447d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html lang=\"en\"><head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
       "<!-- css -->\n",
       "<link href=\"css/all.min.css\" rel=\"stylesheet\"/>\n",
       "<link href=\"css/framework.css\" rel=\"stylesheet\"/>\n",
       "<link href=\"css/master.css\" rel=\"stylesheet\"/>\n",
       "<!-- open graph -->\n",
       "<!-- HTML Meta Tags -->\n",
       "<title>Muhammed Ahmed Abd Al-Aleam</title>\n",
       "<meta content=\"Experienced data analyst with expertise in statistical analysis, data visualization, and machine learning. Skilled in Python and SQL. Passionate about using data to drive business decisions\" name=\"description\"/>\n",
       "<link href=\"assets/logo_v2.ico\" rel=\"shortcut icon\"/>\n",
       "<!-- Facebook Meta Tags -->\n",
       "<meta content=\"https://muhammed-abdelaleam.github.io/me\" property=\"og:url\"/>\n",
       "<meta content=\"website\" property=\"og:type\"/>\n",
       "<meta content=\"Muhammed Ahmed Abd Al-Aleam\" property=\"og:title\"/>\n",
       "<meta content=\"Experienced data analyst with expertise in statistical analysis, data visualization, and machine learning. Skilled in Python and SQL. Passionate about using data to drive business decisions\" property=\"og:description\"/>\n",
       "<meta content=\"https://muhammed-abdelaleam.github.io/me/assets/og.png\" property=\"og:image\"/>\n",
       "<!-- Twitter Meta Tags -->\n",
       "<meta content=\"summary_large_image\" name=\"twitter:card\"/>\n",
       "<meta content=\"muhammed-abdelaleam.github.io\" property=\"twitter:domain\"/>\n",
       "<meta content=\"https://muhammed-abdelaleam.github.io/me\" property=\"twitter:url\"/>\n",
       "<meta content=\"Mohamed Ahmed Abd Al-Aleam\" name=\"twitter:title\"/>\n",
       "<meta content=\"Experienced data analyst with expertise in statistical analysis, data visualization, and machine learning. Skilled in Python and SQL. Passionate about using data to drive business decisions\" name=\"twitter:description\"/>\n",
       "<meta content=\"https://muhammed-abdelaleam.github.io/me/assets/og.png\" name=\"twitter:image\"/>\n",
       "</head>\n",
       "<body>\n",
       "<!-- Header -->\n",
       "<header class=\"h-max\">\n",
       "<nav class=\"flex p\">\n",
       "<div class=\"parent f-sb flex\">\n",
       "<div class=\"name\">Muhammed A.</div>\n",
       "<div class=\"links\" id=\"links\">\n",
       "<a href=\"#\">Home</a>\n",
       "<a href=\"#about\">About</a>\n",
       "<a href=\"#work\">Work</a>\n",
       "<a href=\"#exp\">Experiences</a>\n",
       "<a href=\"muhammed.abdelaleam@gmail.com\">Contact</a>\n",
       "</div>\n",
       "<i class=\"fa-solid fa-bars\" id=\"menu\"></i>\n",
       "</div>\n",
       "</nav>\n",
       "<!-- portfolio -->\n",
       "<div class=\"landing\">\n",
       "<div class=\"parent flex\">\n",
       "<div class=\"left f-1 flex f-col g-20\">\n",
       "<h1 class=\"caption\">\n",
       "              Hello 👋 I am<br/> <span><strong>Muhammed</strong></span> Ahmed Abd Al-Aleam<br/>\n",
       "              Data Analyst.\n",
       "            </h1>\n",
       "<div class=\"des\">\n",
       "            Wish to help you hear what your data is saying to make you get data oriented\n",
       "            decisions and get you out of the messy data and complicated softwares.\n",
       "            </div>\n",
       "<div class=\"btn btn-primary\">Hire Me!</div>\n",
       "</div>\n",
       "<div class=\"right f-1\">\n",
       "<img alt=\"blob\" class=\"blob\" src=\"assets/blob.svg\"/>\n",
       "<div class=\"photo\">\n",
       "<img alt=\"Muhammad Banner\" src=\"assets/banner.png\"/>\n",
       "</div>\n",
       "<div class=\"buble a\">\n",
       "<img alt=\"jubyter\" src=\"assets/jubyter.svg\"/>\n",
       "</div>\n",
       "<div class=\"buble b\">\n",
       "<img alt=\"python\" src=\"assets/python.png\"/>\n",
       "</div>\n",
       "<div class=\"buble c\">\n",
       "<img alt=\"powerpi\" src=\"assets/powerbi.png\"/>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</header>\n",
       "<!-- Header -->\n",
       "<!-- About -->\n",
       "<section class=\"about\" id=\"about\">\n",
       "<div class=\"parent flex\">\n",
       "<div class=\"left f-1 flex\">\n",
       "<img alt=\"data analysis\" src=\"assets/data-science.png\"/>\n",
       "</div>\n",
       "<div class=\"right f-1 flex f-col\">\n",
       "<div class=\"g-label\">About</div>\n",
       "<h2>How can I help you get your project <span><strong>Done</strong></span> 👌</h2>\n",
       "<div class=\"des\">\n",
       "<div></div>\n",
       "<div>Collecting the data using scraping with <span>Selenuim</span> or with APIs.</div>\n",
       "<br/>\n",
       "<div>Advanced cleaninig for data the data using <span>Python</span> libraries.</div>\n",
       "<br/>\n",
       "<div>Querying and more cleaning for the data with <span>SQL</span> to save it.</div>\n",
       "<br/>\n",
       "<div>Doing expalrtory data analysis \"EDA\" with <span>Jupyter notebooks</span> and <span>Plotly</span>.</div>\n",
       "<br/>\n",
       "<div>Asking action-oriented questions with <span>SMART</span> method.</div>\n",
       "<br/>\n",
       "<div>Doing analysis based on the questions with interactive dashboards with <span>Power BI</span> and web dashboards with <span>Chart.js</span></div>\n",
       "<br/>\n",
       "<div>Doing ML models if it's a necessary with <span>TensorFLow</span> or Sklearn and deploy it.</div>\n",
       "</div>\n",
       "<div class=\"btn btn-success\" onclick=\"location.href='assets/resume.pdf'\">\n",
       "            Resume <i class=\"fa-solid fa-download\"></i>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</section>\n",
       "<!-- About -->\n",
       "<!-- Work -->\n",
       "<section class=\"work\" id=\"work\">\n",
       "<div class=\"info p flex\">\n",
       "<div class=\"g-label\">Recent Work</div>\n",
       "</div>\n",
       "<div>*Under construction</div>\n",
       "<div class=\"gallary\">\n",
       "<div class=\"parent flex\" id=\"workE\">\n",
       "<!-- <div class=\"card\">\n",
       "            <div class=\"photo\">\n",
       "              <img\n",
       "                src=\"https://images.unsplash.com/photo-1553342237-c6af5b65a876?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=723&q=80\"\n",
       "                alt=\"work image\"\n",
       "              />\n",
       "            </div>\n",
       "            <div class=\"label\" data-level=\"high\">High</div>\n",
       "            <div class=\"title\">Sample Project</div>\n",
       "            <div class=\"des\">\n",
       "              Lorem ipsum dolor sit amet consectetur adipisicing elit.\n",
       "            </div>\n",
       "          </div> -->\n",
       "<div class=\"card\">\n",
       "<div class=\"photo\">\n",
       "<img alt=\"work image\" src=\"https://placehold.co/500x400\"/>\n",
       "</div>\n",
       "<div class=\"label\" high=\"\" style=\"background-color: red; data-level=\">high</div>\n",
       "<div class=\"title\">Hello world</div>\n",
       "<div class=\"des\">hello</div>\n",
       "</div><div class=\"card\">\n",
       "<div class=\"photo\">\n",
       "<img alt=\"work image\" src=\"https://placehold.co/500x400\"/>\n",
       "</div>\n",
       "<div class=\"label\" medium=\"\" style=\"background-color: red; data-level=\">medium</div>\n",
       "<div class=\"title\">Hello world</div>\n",
       "<div class=\"des\">hello</div>\n",
       "</div><div class=\"card\">\n",
       "<div class=\"photo\">\n",
       "<img alt=\"work image\" src=\"https://placehold.co/500x400\"/>\n",
       "</div>\n",
       "<div class=\"label\" low=\"\" style=\"background-color: red; data-level=\">low</div>\n",
       "<div class=\"title\">Hello world</div>\n",
       "<div class=\"des\">hello</div>\n",
       "</div><div class=\"card\">\n",
       "<div class=\"photo\">\n",
       "<img alt=\"work image\" src=\"https://placehold.co/500x400\"/>\n",
       "</div>\n",
       "<div class=\"label\" high=\"\" style=\"background-color: red; data-level=\">high</div>\n",
       "<div class=\"title\">Hello world</div>\n",
       "<div class=\"des\">hello</div>\n",
       "</div></div>\n",
       "</div>\n",
       "</section>\n",
       "<!-- Work -->\n",
       "<!-- Experience -->\n",
       "<section class=\"exp\" id=\"exp\">\n",
       "<div class=\"info p flex\">\n",
       "<div class=\"g-label\">Experiences</div>\n",
       "</div>\n",
       "<div class=\"parent flex p\">\n",
       "<div class=\"left f-1 flex\">\n",
       "<img alt=\"data analysis\" src=\"assets/certificate.png\"/>\n",
       "</div>\n",
       "<div class=\"right f-1 flex f-col\">\n",
       "<div class=\"line\"></div>\n",
       "<div class=\"cer flex f-col\">\n",
       "<a href=\"#\">Machine Learning (2020 - 2021)</a>\n",
       "<a href=\"#\">Machine Learning (2020 - 2021)</a>\n",
       "<a href=\"#\">Machine Learning (2020 - 2021)</a>\n",
       "<a href=\"#\">Machine Learning (2020 - 2021)</a>\n",
       "<a href=\"#\">Machine Learning (2020 - 2021)</a>\n",
       "<a href=\"#\">Machine Learning (2020 - 2021)</a>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</section>\n",
       "<!-- Experience -->\n",
       "<!-- footer -->\n",
       "<footer>\n",
       "<div class=\"one f-1 p\">\n",
       "<div class=\"parent flex\">\n",
       "<div class=\"left\">\n",
       "<h2>Muhammad Ahmed Abd Al-Aleam</h2>\n",
       "<div class=\"des\">\n",
       "              Experienced data analyst with expertise in statistical analysis,\n",
       "              data visualization, and machine learning. Skilled in Python, and\n",
       "              SQL.\n",
       "            </div>\n",
       "</div>\n",
       "<div class=\"right p\">\n",
       "<a href=\"https://www.linkedin.com/in/muhammed-ahmed-abd-al-aleam-elsayegh-4758ba248/\"><i class=\"fa-brands fa-linkedin\"></i> Linked In</a>\n",
       "<a href=\"https://github.com/muhammed-abdelaleam\"><i class=\"fa-brands fa-github\"></i> GitHub</a>\n",
       "<a href=\"muhammed.abdelaleam@gmail.com\"><i class=\"fa-solid fa-inbox\"></i> Email</a>\n",
       "<a href=\"https://twitter.com/M_AbdAlAleam\"><i class=\"fa-brands fa-twitter\"></i> Twitter</a>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"two p\">\n",
       "        Made With ❤ By\n",
       "        <a href=\"https://mszakii.github.io/me\">Mohamed E. Zaky</a>\n",
       "</div>\n",
       "</footer>\n",
       "<!-- footer -->\n",
       "<!-- master -->\n",
       "<script src=\"js/master.js\"></script>\n",
       "</body></html>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_page(\"https://muhammed-abdelaleam.github.io/me/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b219d160-162a-4860-9116-60302878d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = {\"soup_name\": [],\n",
    "         \"soup_job_type\": [],\n",
    "         \"soup_job_title\": [],\n",
    "         \"soup_page\":  [],\n",
    "         \"soup\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d79a77b-f579-4750-984a-599fa9df13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the job type is services in upwork the pages paremeter will refer to how many pages \n",
    "# will render at once while the other scrapers will render the spesfic spesfied page only.\n",
    "\n",
    "def get_all_pages_soups(pph_type, freelancer_type, upwork_type, guru_type, max_page: int= 999) -> dict:\n",
    "\n",
    "    print(\"Strating ...\")\n",
    "    for i in count(0):\n",
    "\n",
    "        global orgnaize_data_in_dict\n",
    "        page = i + 1\n",
    "\n",
    "        print(f\"Loading page {page} of each website ...\")\n",
    "\n",
    "        for data_job_title in data_jobs_titles:\n",
    "\n",
    "            lines = [f'peopleperhour_html = peopleperhour_scraper({page}, \"{data_job_title}\", \"{pph_type}\")',\n",
    "                     f'fivver_html = fivver_scraper({page}, \"{data_job_title}\")',\n",
    "                     f'freelancer_html = freelancer_scraper({page}, \"{data_job_title}\", \"{freelancer_type}\")',\n",
    "                     f'upwork_html = upwork_scraper({page}, \"{data_job_title}\", \"{upwork_type}\")',\n",
    "                     f'guru_html = guru_scraper({page}, \"{data_job_title}\", \"{guru_type}\")']\n",
    "\n",
    "            for line_idx, line in enumerate(lines):\n",
    "\n",
    "                equall_sign_idx = line.find('=')\n",
    "\n",
    "                def orgnaize_data_in_dict():\n",
    "                    soups[\"soup_job_title\"].append(data_job_title)\n",
    "                    soups[\"soup_name\"].append(line[:equall_sign_idx])\n",
    "                    soups[\"soup_page\"].append(page)\n",
    "                    soups[\"soup\"].append(exec(line[:equall_sign_idx]))\n",
    "                    soups[\"soup_job_type\"].append(job_type)\n",
    "\n",
    "                try:\n",
    "                    print(line)\n",
    "                    exec(line)\n",
    "                    orgnaize_data_in_dict()\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "\n",
    "                    print(e)\n",
    "                    del lines[line_idx]\n",
    "                    if len(lines) < 1 or page >= max_page:\n",
    "\n",
    "                        print(\"Finished ...\")\n",
    "                        return  soups\n",
    "                        break\n",
    "\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3c985db-6dab-4034-998f-aa6645e2a9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strating ...\n",
      "Loading page 1 of each website ...\n",
      "peopleperhour_html = peopleperhour_scraper(1, \"data-entry\", \"freelance-jobs\")\n",
      "name 'peopleperhour_html' is not defined\n",
      "Finished ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'soup_name': ['peopleperhour_html ',\n",
       "  'freelancer_html ',\n",
       "  'peopleperhour_html ',\n",
       "  'peopleperhour_html '],\n",
       " 'soup_job_type': [],\n",
       " 'soup_job_title': ['data-entry', 'data-entry', 'data-entry', 'data-entry'],\n",
       " 'soup_page': [1, 1, 1, 1],\n",
       " 'soup': []}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_pages_soups(\"freelance-jobs\", \"projects\", \"jobs\", \"jobs\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85626097-1809-40b9-a17c-ff3538cb1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col1': [1, 2, 3, 5, 5], 'col2': [1, 2, 3, 9, nan]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"col1\": [1, 2, 3, 5, 5],\n",
    "        \"col2\": [1, 2, 3, 9]}\n",
    "\n",
    "max_length = max(len(lst) for lst in dict.values())\n",
    "dict = {key: lst + [float('nan')] * (max_length - len(lst)) for key, lst in dict.items()}\n",
    "\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7ce831-bd81-4a23-b771-30457a6a1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the title of each page to check if it's loaded correctly.\n",
      "\n",
      "-\t Freelance Data-analytics Jobs - Upwork\n",
      "-\t Data Analytics Services Online | Fiverr\n",
      "-\t Machine Learning Freelance Jobs Online - Guru\n",
      "-\t Get Data Analytics Offers & Services | PeoplePerHour\n",
      "-\t Users Jobs, Employment | Freelancer\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing the title of each page to check if it's loaded correctly.\\n\")\n",
    "\n",
    "for soup in soups[\"soup\"]:\n",
    "    print(\"-\\t\", soup.title.text.replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "\n",
    "soups = pd.DataFrame(soups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db860af4-9005-4f07-8bfa-cab4cdb3aa87",
   "metadata": {},
   "source": [
    "Looks like everything is working as expected now let's start reel work by extracting the HTML tags data from the scraped<br>\n",
    "pages.<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac5af7-1f3f-44a7-b93b-778e70096067",
   "metadata": {},
   "source": [
    "But we will need to collect the data from each one of those pages with unique way further more we need to optimize the<br>\n",
    "data extractor to collect the data from other pages from the same site like \"jobs\" site and \"profiles\" sites on upwork.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dfb3b7e-ed6c-49db-a27b-05e963d689ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cards_links(soup_name, tag, link_template,\n",
    "                    link_attr, tag_class, attr= \"class\") -> list:\n",
    "\n",
    "    soup = soups[soups[\"soup_name\"] == soup_name][\"soup\"].values[0]\n",
    "\n",
    "    cards = soup.find_all(tag, attrs= {attr: tag_class})\n",
    "    cards_ids = []\n",
    "\n",
    "    if link_attr != \"\":\n",
    "\n",
    "        for card in cards:\n",
    "\n",
    "            card_id = link_template.replace(\"###\", card[link_attr])\n",
    "\n",
    "            if len(card_id) > len(link_template):\n",
    "                cards_ids.append(card_id)\n",
    "\n",
    "        return  cards_ids\n",
    "\n",
    "    else:\n",
    "        return  cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "710987e9-6eb6-47cd-a8ec-8d1777445501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't collect guru data this wat becuase it has slightly deffrint case in terms\n",
    "# of collecting the jobs URLs\n",
    "\n",
    "## --------------------------Upwork--------------------------\n",
    "upwork_gigs_links = get_cards_links('upwork_soup', 'a', 'https://upwork.com###', 'href',\n",
    "                                        'up-n-link project-tile up-card m-0 p-0 up-card-section up-card-hover project-tile_flexible')\n",
    "\n",
    "upwork_profiles_links = get_cards_links('upwork_soup', 'div', 'https://www.upwork.com/search/profiles/?profile=###', 'data-test-key',\n",
    "                                         'up-card-section up-card-hover')\n",
    "\n",
    "upwork_jobs_parents = get_cards_links('upwork_soup', 'h3', 'https://www.upwork.com###', '', 'my-0 p-sm-right job-tile-title')\n",
    "upwork_jobs_links = []\n",
    "\n",
    "for parent in upwork_jobs_parents:\n",
    "    upwork_jobs_links.append(\"https://www.upwork.com\" + parent.find('a', class_= \"up-n-link\")['href'])\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## --------------------------Fivver--------------------------\n",
    "fivver_gigs_links = get_cards_links('fivver_soup', 'a', 'https://www.fiverr.com###', 'href', 'tbody-5 p-t-4 YLycza2 u9KHmsf')\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## ---------------------People per hour----------------------\n",
    "pph_services_links = get_cards_links(\"peopleperhour_soup\", \"a\", \"https://www.peopleperhour.com###\", \"href\", \n",
    "                                     \"card__title-wrapper⤍FreelancerCard⤚2-NWk\")\n",
    "\n",
    "pph_freelancers_links = get_cards_links(\"peopleperhour_soup\", \"a\", \"https://www.peopleperhour.com###\", \"href\",\n",
    "                                        \"card__title-wrapper⤍FreelancerCard⤚2-NWk\")\n",
    "\n",
    "pph_jobs_links = get_cards_links(\"peopleperhour_soup\", \"a\", \"https://www.peopleperhour.com###\", \"href\",\n",
    "                                 \"item__url⤍ListItem⤚20ULx\")\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## ------------------------Guru------------------------------\n",
    "guru_cards_parents_profiles = get_cards_links(\"guru_soup\", \"h2\", \"https://guru.com###\", \"\",\n",
    "                                              \"jobRecord__title jobRecord__title--changeVisited\")\n",
    "\n",
    "guru_cards_parents_jobs = get_cards_links(\"guru_soup\", \"h2\", \"https://guru.com###\", \"\",\n",
    "                                          \"jobRecord__title jobRecord__title--changeVisited\")\n",
    "## ----------------------------------------------------------\n",
    "\n",
    "\n",
    "## ----------------------Freelancer---------------------------\n",
    "freelancer_jobs_links = get_cards_links(\"freelancer_soup\", \"a\", \"https://www.freelancer.com###\", \"href\",\n",
    "                                        \"LinkElement ng-star-inserted\")\n",
    "\n",
    "freelancer_freelancers_links = get_cards_links(\"freelancer_soup\", \"a\", \"https://www.freelancer.com###\", \"href\",\n",
    "                                              \"LinkElement ng-star-inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04a0cdb0-c6ac-426d-a893-ce8897ccbc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freelancer_freelancers_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1caa82-9049-40af-9248-5a6dcf4d404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upwork_links(job_type: str) -> list:  \n",
    "\n",
    "    card_tag = \"a\"\n",
    "    link_template = \"https://www.upwork.com###\"\n",
    "    link_attr = \"href\"\n",
    "\n",
    "    if job_type == \"profiles\":\n",
    "\n",
    "        card_tag = \"div\"\n",
    "        card_tag_class = \"up-card-section up-card-hover\"\n",
    "        link_template = \"https://www.upwork.com/search/profiles/?q=profiles&profile=###\"\n",
    "        link_attr = \"data-test-key\"\n",
    "    \n",
    "    elif job_type == \"jobs\":\n",
    "        card_tag_class = \"up-n-link\"\n",
    "\n",
    "\n",
    "    elif job_type == \"services\":\n",
    "        card_tag_class = \"up-n-link project-tile up-card m-0 p-0 up-card-section up-card-hover project-tile_flexible\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Please input correct work type from ['profiles', 'jobs', 'services'].\")\n",
    "\n",
    "\n",
    "    soup = soups[soups[\"soup_name\"] == \"upwork_soup\"][\"soup\"][0]\n",
    "\n",
    "    cards = soup.find_all(card_tag, class_= card_tag_class)\n",
    "    cards_ids = []\n",
    "\n",
    "    for card in cards:\n",
    "        \n",
    "        card_id = link_template.replace(\"###\", card[link_attr])\n",
    "        \n",
    "        if len(card_id) > len(link_template):\n",
    "            cards_ids.append(card_id)\n",
    "\n",
    "    return  cards_ids\n",
    "\n",
    "\n",
    "def get_fivver_links() -> list:\n",
    "\n",
    "    card_tag = \"div\"\n",
    "    card_tag_class = \"basic-gig-card\"\n",
    "    link_template = \"https://www.fiverr.com###\"\n",
    "    link_attr = \"href\"\n",
    "\n",
    "    cards = soup.find_all(card_tag, class_= card_tag_class)\n",
    "    cards_ids = []\n",
    "    \n",
    "    for card in cards:\n",
    "        \n",
    "        card_id = link_template.replace(\"###\", card[link_attr])\n",
    "        \n",
    "        if len(card_id) > len(link_template):\n",
    "            cards_ids.append(card_id)\n",
    "\n",
    "    return  cards_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8189c7-4417-4b58-82f6-e1b634d4aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guru_links(job_type: str) -> list:  \n",
    "\n",
    "    soup = soups[soups[\"soup_name\"] == \"guru_soup\"][\"soup\"][2]\n",
    "    link_template = \"https://www.guru.com###\"\n",
    "\n",
    "    if job_type == \"freelancers\":\n",
    "        cards_parents = soup.find_all(\n",
    "            'h2', class_= 'serviceListing__title serviceListing__title--dark')\n",
    "\n",
    "        cards = []\n",
    "\n",
    "        for parent in cards_parents:\n",
    "            card = parent.find('a')\n",
    "            cards.append(card)\n",
    "\n",
    "    elif job_type == \"jobs\":\n",
    "        cards_parents = soup.find_all(\n",
    "            'h2', class_ = 'jobRecord__title jobRecord__title--changeVisited')\n",
    "\n",
    "        cards = []\n",
    "\n",
    "        for parent in cards_parents:\n",
    "            card = parent.find('a')\n",
    "            cards.append(card)\n",
    "\n",
    "    cards_ids = []\n",
    "\n",
    "    for card in cards:\n",
    "        card_id = link_template.replace(\"###\", card['href'])\n",
    "        cards_ids.append(card_id)\n",
    "\n",
    "    return  cards_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e58f11-9b8e-4ee0-bf80-8405af334fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_guru_links('jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd419a-7ce6-4b9f-a30b-43b66e59de47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
